{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649a7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import evaluate\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainingArguments\n",
    "from transformers import Seq2SeqTrainer, DataCollatorForSeq2Seq, TrainerCallback, T5Config\n",
    "\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchsummary import summary\n",
    "\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9257d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Sample:\n",
      "                                 question  \\\n",
      "0                What is (are) Glaucoma ?   \n",
      "1                  What causes Glaucoma ?   \n",
      "2     What are the symptoms of Glaucoma ?   \n",
      "3  What are the treatments for Glaucoma ?   \n",
      "4                What is (are) Glaucoma ?   \n",
      "\n",
      "                                              answer           source  \\\n",
      "0  Glaucoma is a group of diseases that can damag...  NIHSeniorHealth   \n",
      "1  Nearly 2.7 million people have glaucoma, a lea...  NIHSeniorHealth   \n",
      "2  Symptoms of Glaucoma  Glaucoma can develop in ...  NIHSeniorHealth   \n",
      "3  Although open-angle glaucoma cannot be cured, ...  NIHSeniorHealth   \n",
      "4  Glaucoma is a group of diseases that can damag...  NIHSeniorHealth   \n",
      "\n",
      "  focus_area  \n",
      "0   Glaucoma  \n",
      "1   Glaucoma  \n",
      "2   Glaucoma  \n",
      "3   Glaucoma  \n",
      "4   Glaucoma  \n",
      "Null Value Data:\n",
      "question       0\n",
      "answer         5\n",
      "source         0\n",
      "focus_area    14\n",
      "dtype: int64\n",
      "Number of duplicate rows: 48\n",
      "Table Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16364 entries, 0 to 16363\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  16364 non-null  object\n",
      " 1   answer    16359 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 255.8+ KB\n",
      "None\n",
      "Null Value Data After Cleaning:\n",
      "question    0\n",
      "answer      0\n",
      "dtype: int64\n",
      "Unique questions: 13843\n",
      "Unique answers: 13851\n",
      "Final Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13857 entries, 0 to 13856\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  13857 non-null  object\n",
      " 1   answer    13857 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 216.6+ KB\n",
      "Final Data Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is glaucoma ?</td>\n",
       "      <td>glaucoma is a group of diseases that can damag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what causes glaucoma ?</td>\n",
       "      <td>nearly 2.7 million people have glaucoma, a lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what are the symptoms of glaucoma ?</td>\n",
       "      <td>symptoms of glaucoma glaucoma can develop in o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what are the treatments for glaucoma ?</td>\n",
       "      <td>although open-angle glaucoma cannot be cured, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who is at risk for glaucoma? ?</td>\n",
       "      <td>anyone can develop glaucoma. some people are a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 question  \\\n",
       "0                      what is glaucoma ?   \n",
       "1                  what causes glaucoma ?   \n",
       "2     what are the symptoms of glaucoma ?   \n",
       "3  what are the treatments for glaucoma ?   \n",
       "4          who is at risk for glaucoma? ?   \n",
       "\n",
       "                                              answer  \n",
       "0  glaucoma is a group of diseases that can damag...  \n",
       "1  nearly 2.7 million people have glaucoma, a lea...  \n",
       "2  symptoms of glaucoma glaucoma can develop in o...  \n",
       "3  although open-angle glaucoma cannot be cured, ...  \n",
       "4  anyone can develop glaucoma. some people are a...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from a CSV file\n",
    "df = pd.read_csv('../data/medquad.csv')\n",
    "\n",
    "# Display a sample of the data to understand its structure\n",
    "print(\"Data Sample:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for null values in the dataset\n",
    "print(\"Null Value Data:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Define a list of common question words to filter relevant questions\n",
    "question_words = ['what', 'who', 'why', 'when', 'where', 'how', 'is', 'are', 'does', 'do', 'can', 'will', 'shall']\n",
    "\n",
    "# Convert all questions to lowercase for consistent filtering\n",
    "df['question'] = df['question'].str.lower()\n",
    "\n",
    "# Filter rows where the question starts with one of the question words\n",
    "df = df[df['question'].str.split().str[0].isin(question_words)]\n",
    "\n",
    "# Reset the index after filtering\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Check for duplicate rows in the dataset\n",
    "duplicates = df.duplicated()\n",
    "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
    "\n",
    "# Remove duplicate rows to ensure data uniqueness\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Reset the index after removing duplicates\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Drop unused columns ('source' and 'focus_area') to simplify the dataset\n",
    "df = df.drop(columns=['source', 'focus_area'])\n",
    "\n",
    "# Display dataset information (columns, data types, and non-null counts)\n",
    "print(\"Table Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Remove duplicate rows based on the 'question' and 'answer' columns\n",
    "df = df.drop_duplicates(subset='question', keep='first').reset_index(drop=True)\n",
    "df = df.drop_duplicates(subset='answer', keep='first').reset_index(drop=True)\n",
    "\n",
    "# Drop rows with null values in the 'question' or 'answer' columns\n",
    "df = df.dropna(subset=['question', 'answer']).reset_index(drop=True)\n",
    "\n",
    "# Fill any remaining null values with empty strings and convert to string type\n",
    "df['question'] = df['question'].fillna('').astype(str)\n",
    "df['answer'] = df['answer'].fillna('').astype(str)\n",
    "\n",
    "# Define a function to clean text by removing parentheses and extra spaces\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"\\(.*?\\)\", \"\", text)  # Remove text within parentheses\n",
    "    text = re.sub(r'\\s+', ' ', text.strip().lower())  # Normalize spaces and convert to lowercase\n",
    "    return text\n",
    "\n",
    "# Apply the clean_text function to the 'question' and 'answer' columns\n",
    "df['question'] = df['question'].apply(clean_text)\n",
    "df['answer'] = df['answer'].apply(clean_text)\n",
    "\n",
    "# Further clean the text by ensuring lowercase, stripping whitespace, and normalizing spaces\n",
    "df['question'] = df['question'].str.lower().str.strip().apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "df['answer'] = df['answer'].str.lower().str.strip().apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "\n",
    "# Check for null values again after cleaning\n",
    "print(\"Null Value Data After Cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check the number of unique questions and answers in the dataset\n",
    "print(f\"Unique questions: {df['question'].nunique()}\")\n",
    "print(f\"Unique answers: {df['answer'].nunique()}\")\n",
    "\n",
    "# Display dataset information and a sample of the cleaned data\n",
    "print(\"Final Dataset Info:\")\n",
    "df.info()\n",
    "print(\"Final Data Sample:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1305b309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Model Summary:\n",
      "==================================================\n",
      "Layer Type                    Count     Parameters     \n",
      "=======================================================\n",
      "T5ForConditionalGeneration    1         222,882,048    \n",
      "Embedding                     3         24,653,568     \n",
      "T5Stack                       2         247,534,848    \n",
      "ModuleList                    26        396,455,424    \n",
      "T5Block                       24        198,227,712    \n",
      "T5LayerSelfAttention          24        56,642,304     \n",
      "T5Attention                   36        84,935,424     \n",
      "Linear                        193       222,833,664    \n",
      "T5LayerNorm                   62        47,616         \n",
      "Dropout                       86        0              \n",
      "T5LayerFF                     24        113,264,640    \n",
      "T5DenseActDense               24        113,246,208    \n",
      "ReLU                          24        0              \n",
      "T5LayerCrossAttention         12        28,320,768     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37e2a52781048b3a591251c583ae3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/11778 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5419a52f09d4df69c97b27a675cf7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2079 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='737' max='737' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [737/737 49:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.922300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.572900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.426900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.439600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.376700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.307500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.328100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model name and load the T5 configuration\n",
    "model_name = \"t5-base\"\n",
    "config = T5Config.from_pretrained(model_name)\n",
    "\n",
    "# Customize the configuration\n",
    "config.dropout_rate = 0.1  # Set dropout rate to 0.1 for regularization\n",
    "config.feed_forward_proj = \"gelu\"  # Use GELU activation for the feed-forward layers\n",
    "\n",
    "# Load the pre-trained T5 model with the customized configuration\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, config=config)\n",
    "\n",
    "# Load the tokenizer for the T5 model\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Explicitly resize the token embeddings to match the tokenizer's vocabulary size\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Print a detailed summary of the model architecture\n",
    "print(\"\\nDetailed Model Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def summarize_model_by_type(model):\n",
    "    \"\"\"\n",
    "    Summarizes the model by counting the number of layers and parameters for each layer type.\n",
    "    \"\"\"\n",
    "    layer_summary = defaultdict(int)  # Counts the number of layers by type\n",
    "    param_summary = defaultdict(int)  # Counts the number of parameters by layer type\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        layer_type = type(module).__name__  # Get the type of the current module\n",
    "        layer_summary[layer_type] += 1  # Increment the count for this layer type\n",
    "        param_summary[layer_type] += sum(p.numel() for p in module.parameters())  # Sum parameters\n",
    "\n",
    "    # Print the summary table\n",
    "    print(f\"{'Layer Type':<30}{'Count':<10}{'Parameters':<15}\")\n",
    "    print(\"=\" * 55)\n",
    "    for layer_type, count in layer_summary.items():\n",
    "        print(f\"{layer_type:<30}{count:<10}{param_summary[layer_type]:<15,}\")\n",
    "\n",
    "summarize_model_by_type(model)\n",
    "\n",
    "# Define a preprocessing function for the seq2seq task (optimized for speed)\n",
    "def preprocess_function(batch):\n",
    "    \"\"\"\n",
    "    Preprocesses the dataset by tokenizing the inputs and targets.\n",
    "    Optimized for speed by using fast tokenization and avoiding unnecessary conversions.\n",
    "    \"\"\"\n",
    "    # Format the inputs and targets\n",
    "    inputs = [f\"answer the following question: {q}\" for q in batch['question']]\n",
    "    targets = [str(a) for a in batch['answer']]\n",
    "\n",
    "    # Tokenize the inputs and targets in one call each, return as lists (not tensors)\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            targets,\n",
    "            max_length=64,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "\n",
    "    # Replace padding token IDs with -100 for the loss function to ignore them\n",
    "    labels_ids = [\n",
    "        [(lid if lid != tokenizer.pad_token_id else -100) for lid in label]\n",
    "        for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "    model_inputs[\"labels\"] = labels_ids\n",
    "    return model_inputs\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.15, random_state=42)\n",
    "\n",
    "# Convert the pandas DataFrames to Hugging Face Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "# Preprocess the training and validation datasets\n",
    "train_dataset = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=16,  # Process in batches of 16\n",
    "    remove_columns=train_dataset.column_names,  # Remove original columns\n",
    "    num_proc=4,  # Use 4 processes for parallel processing\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=16,  # Process in batches of 16\n",
    "    remove_columns=val_dataset.column_names,  # Remove original columns\n",
    "    num_proc=4,  # Use 4 processes for parallel processing\n",
    ")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    do_eval=True,\n",
    "    save_total_limit=1,  # Guarda solo el último checkpoint para ahorrar espacio\n",
    "    learning_rate=5e-4,  # Puedes subirlo a 1e-3 para convergencia más rápida, pero cuidado con la estabilidad\n",
    "    num_train_epochs=1,  # Solo 1 época para pruebas rápidas\n",
    "    per_device_train_batch_size=16,  # Aumenta el batch size si tu RAM lo permite\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_ratio=0.05,  # Menor warmup para acelerar el inicio\n",
    "    weight_decay=0.01,  # Menor regularización para acelerar el aprendizaje\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    no_cuda=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,  # Menos logs para menos overhead\n",
    "    gradient_accumulation_steps=1,  # Sin acumulación para pasos más rápidos\n",
    "    max_grad_norm=1.0,\n",
    "    dataloader_num_workers=2,\n",
    "    group_by_length=True,\n",
    "    remove_unused_columns=True,\n",
    "    label_smoothing_factor=0.05,\n",
    ")\n",
    "\n",
    "# Initialize the data collator for seq2seq tasks\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding='longest',  # Pad sequences to the longest in the batch\n",
    "    return_tensors=\"pt\",  # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "# Define a function to compute evaluation metrics\n",
    "def compute_metrics(eval_pred, tokenizer):\n",
    "    \"\"\"\n",
    "    Computes exact match, BLEU, and ROUGE-L metrics for evaluation.\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Decode predictions and labels\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Normalize text for comparison\n",
    "    decoded_preds = [text.strip().lower() for text in decoded_preds]\n",
    "    decoded_labels = [text.strip().lower() for text in decoded_labels]\n",
    "\n",
    "    # Compute exact match\n",
    "    exact_match = np.mean([p == l for p, l in zip(decoded_preds, decoded_labels)])\n",
    "\n",
    "    # Load BLEU and ROUGE metrics\n",
    "    bleu_metric = evaluate.load(\"bleu\")\n",
    "    rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "    # Compute BLEU score\n",
    "    bleu_score = bleu_metric.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=[[label] for label in decoded_labels]\n",
    "    )[\"bleu\"]\n",
    "\n",
    "    # Compute ROUGE-L score\n",
    "    rouge_score = rouge_metric.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=decoded_labels\n",
    "    )[\"rougeL\"]\n",
    "\n",
    "    return {\n",
    "        \"exact_match\": exact_match,\n",
    "        \"BLEU\": bleu_score,\n",
    "        \"ROUGE-L\": rouge_score,\n",
    "    }\n",
    "\n",
    "# Initialize the Seq2SeqTrainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=lambda eval_pred: compute_metrics(eval_pred, tokenizer),\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model and tokenizer\n",
    "trainer.save_model(\"./t5_chatbot_model\")\n",
    "tokenizer.save_pretrained(\"./t5_chatbot_tokenizer\")\n",
    "\n",
    "# Save the model's state dictionary\n",
    "model_path = \"./t5_chatbot_model.h5\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Save the training log history\n",
    "log_history = trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c904ce3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store training and evaluation metrics\n",
    "train_loss = []  # To store training loss values\n",
    "eval_loss = []  # To store evaluation loss values\n",
    "eval_bleu = []  # To store BLEU scores during evaluation\n",
    "eval_exact_match = []  # To store exact match scores during evaluation\n",
    "eval_rogue = []  # To store ROUGE-L scores during evaluation\n",
    "steps = []  # To store training step numbers\n",
    "eval_steps = []  # To store evaluation step numbers\n",
    "\n",
    "# Extract metrics from the training log history\n",
    "for log in log_history:\n",
    "    if \"loss\" in log:  # Check if training loss is in the log\n",
    "        train_loss.append(log[\"loss\"])  # Append training loss\n",
    "        steps.append(log[\"step\"])  # Append the corresponding step number\n",
    "    if \"eval_loss\" in log:  # Check if evaluation loss is in the log\n",
    "        eval_loss.append(log[\"eval_loss\"])  # Append evaluation loss\n",
    "        eval_steps.append(log[\"step\"])  # Append the corresponding step number\n",
    "    if \"eval_BLEU\" in log:  # Check if BLEU score is in the log\n",
    "        eval_bleu.append(log[\"eval_BLEU\"])  # Append BLEU score\n",
    "    if \"eval_ROUGE-L\" in log:  # Check if ROUGE-L score is in the log\n",
    "        eval_rogue.append(log[\"eval_ROUGE-L\"])  # Append ROUGE-L score\n",
    "    if \"eval_exact_match\" in log:  # Check if exact match score is in the log\n",
    "        eval_exact_match.append(log[\"eval_exact_match\"])  # Append exact match score\n",
    "\n",
    "# Plot the training and evaluation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(steps, train_loss, label=\"Training Loss\", color=\"blue\", marker=\"o\")  # Plot training loss\n",
    "plt.plot(steps[:len(eval_loss)], eval_loss, label=\"Evaluation Loss\", color=\"orange\", marker=\"o\")  # Plot evaluation loss\n",
    "plt.xlabel(\"Training Steps\")  # X-axis label\n",
    "plt.ylabel(\"Loss\")  # Y-axis label\n",
    "plt.title(\"Training vs Evaluation Loss\")  # Plot title\n",
    "plt.legend()  # Show legend\n",
    "plt.grid(True)  # Add grid for better readability\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Plot the BLEU score over training steps\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(eval_steps, eval_bleu, label=\"BLEU\", marker=\"o\", linestyle=\"-\", color=\"green\")  # Plot BLEU score\n",
    "plt.xlabel(\"Training Steps\")  # X-axis label\n",
    "plt.ylabel(\"Metric Score\")  # Y-axis label\n",
    "plt.title(\"BLEU Score Over Training Steps\")  # Plot title\n",
    "plt.legend()  # Show legend\n",
    "plt.grid(True)  # Add grid for better readability\n",
    "plt.tight_layout()  # Adjust layout for better spacing\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Plot the ROUGE-L score over training steps\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(eval_steps, eval_rogue, label=\"ROUGE-L\", marker=\"o\", linestyle=\"-\", color=\"red\")  # Plot ROUGE-L score\n",
    "plt.xlabel(\"Training Steps\")  # X-axis label\n",
    "plt.ylabel(\"Metric Score\")  # Y-axis label\n",
    "plt.title(\"ROUGE-L Score Over Training Steps\")  # Plot title\n",
    "plt.legend()  # Show legend\n",
    "plt.grid(True)  # Add grid for better readability\n",
    "plt.tight_layout()  # Adjust layout for better spacing\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Plot the exact match score over training steps\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(eval_steps, eval_exact_match, label=\"Exact Match\", marker=\"o\", linestyle=\"-\", color=\"black\")  # Plot exact match score\n",
    "plt.xlabel(\"Training Steps\")  # X-axis label\n",
    "plt.ylabel(\"Metric Score\")  # Y-axis label\n",
    "plt.title(\"Exact Match Over Training Steps\")  # Plot title\n",
    "plt.legend()  # Show legend\n",
    "plt.grid(True)  # Add grid for better readability\n",
    "plt.tight_layout()  # Adjust layout for better spacing\n",
    "plt.show()  # Display the plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
